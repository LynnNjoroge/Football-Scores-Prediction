# -*- coding: utf-8 -*-
"""Moringa_DSCore_IP_Week_6_Lynn_Njoroge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eJTz8FqfqDoGftA15YVRMiN5aXAVNXy5

## 1. Defining the Question

### a) Specifying the Question

We have been recruited as football analysts by Mchezopesa Ltd to predict results of a game between team 1 and team 2, based on who's home and who's away, and on whether or not the game is friendly (We Should include rank in our training)

### b) Defining the Metric for Success

For this analysis to be considered successful, we must be able to create an effective model that will be able to:

1. Perform EDA.
2. Predict how many goals the home team scores.
3. Predict how many goals the away team scores.
4. Figure out from the home team’s perspective if the game is a Win, Lose or Draw (W, L, D)
5. Achieve an RMSE score that is less than 10% of the target mean
6. Achieve a high accuracy  score

### c) Understanding the context

The men's FIFA World Ranking is a ranking system for men's national teams in association football. The teams of the men's member nations of FIFA, football's world governing body, are ranked based on their game results with the most successful teams being ranked highest. The rankings were introduced in December 1992.

How the rankings are calculated:

The rankings are calculated using an algorithm called Elo. The Elo method of calculation adds/subtracts points (as opposed to averaging points) for individual matches to/from a team’s existing point total. The points which are added or subtracted are partially determined by the relative strength of the two opponents, including the logical expectation that teams higher in the ranking should fare better against teams lower in the ranking.

The dataset and glossary for this analysis can be found here https://drive.google.com/open?id=1BYUqaEEnFtAe5lvzJh9lpVpR2MAvERUc

### d) Recording the Experimental Design

The following steps will be followed in conducting this analysis:

1. Defining the Question
2. Reading the Data.
3. Checking the Data.
4. Data Cleaning
5. Merging the Dataframes
6. Performing EDA
7. Prediction Models
8. Evaluation of the solution
9. Challenging the solution
10. Conclusion

### e) Data Relevance

This will be discussed after the analysis and prediction has been completed

## Reading the Data

### Importing our Libraries
"""

# installing the necessary libraries not in google colab
! pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip

# Commented out IPython magic to ensure Python compatibility.
# Let us first import all the libraries we will need for our analysis
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib
from matplotlib import pyplot as plt
# %matplotlib inline
from pandas_profiling import ProfileReport
from scipy import stats
from scipy.stats import norm
from scipy.stats import t
import math
from scipy.stats import ttest_ind
import statsmodels.api as sm

# let us set the warnings that may appear in our analysis off

import warnings
warnings.filterwarnings('ignore') 

# subsequently let us set the pandas warning for chained assignments off
pd.options.mode.chained_assignment = None  # default='warn'

"""### Loading and Previewing our Dataset"""

# Loading the Dataset from the source i.e. csv
rank = pd.read_csv('/content/fifa_ranking.csv')
rank.head()

result = pd.read_csv('/content/results.csv')
result.head()

"""## Checking the Data

### The Ranking Dataset
"""

# Determining the no. of records in our dataset
#
print('This rank dataset has ' + str(rank.shape[0]) + ' rows, and ' + str(rank.shape[1]) + ' columns')

# Checking whether each column has an appropriate datatype
#
rank.dtypes

# checking the dataset information

rank.info()

# Let us view the summary statistics of our dataset

rank.describe()

# let us see the columns in our dataframe
rank.columns

# Checking the entire profile of the dataframe

profile = ProfileReport(rank, title="Rank Dataset Profile Report", html={'style':{'full_width':True}})
profile.to_notebook_iframe()

# let us save our profile report
profile.to_file(output_file="Rank_Dataset_Profile_Report.html")

"""### The Result Dataset"""

# Determining the no. of records in our dataset
#
print('This rank dataset has ' + str(result.shape[0]) + ' rows, and ' + str(result.shape[1]) + ' columns')

# Checking whether each column has an appropriate datatype
#
result.dtypes

# checking the dataset information

result.info()

# Let us view the summary statistics of our dataset

result.describe()

# let us see the columns in our dataframe
result.columns

# Checking the entire profile of the dataframe

profile = ProfileReport(result, title="Result Dataset Profile Report", html={'style':{'full_width':True}})
profile.to_notebook_iframe()

# let us save our profile report
profile.to_file(output_file="Result_Dataset_Profile_Report.html")

"""## Data Cleaning

### The Rank Dataset
"""

# From our profile report, we can see that we don't have any duplicated rows
# But let us check 
rank.duplicated().sum()

# let us drop our duplicates
rank.drop_duplicates(inplace=True)
rank.duplicated().sum()

# Let Us Drop columns we will not need for this analysis
# We are dealing with rank in this analysis so, 
# we don't need columns unrelated to rank.

rank.drop(['country_abrv','total_points','previous_points','cur_year_avg',
           'cur_year_avg_weighted', 'last_year_avg','last_year_avg_weighted','two_year_ago_avg',
           'two_year_ago_weighted','three_year_ago_avg','three_year_ago_weighted'], axis = 1, inplace = True)

# let us confirm that we have dropped the unnecessary columns
rank.head()

# Let us see if we have any null values
rank.isnull().sum()

# Checking for Anomalies
# Checking for outliers in the columns with numerical data

# let us print out the IQR for each numerical column
Q1 = rank.quantile(0.25)
Q3 = rank.quantile(0.75)
IQR = Q3 - Q1
print(IQR)

# let us drop the outliers and see hpw much data we lose
rank_out = rank[~((rank < (Q1 - 1.5 * IQR)) |(rank > (Q3 + 1.5 * IQR))).any(axis=1)]
rank_out.shape
# outliers are 21,722 records. which is noy a big chunk of our data.

# We decided not to drop outliers 
# because dropping such a large part of our data would seriously affect the validity of our results 
# now that we have a clean dataset, let us carry out our analysis

# changing the date column to pandas datetime 
rank.rank_date = pd.to_datetime(rank.rank_date)
rank.dtypes

"""### The Results Dataset"""

# From our profile report, we can see that we don't have any duplicated rows
# But let us check 
result.duplicated().sum()

# Let Us Drop columns we will not need for this analysis
# We don't need the city column.

result.drop(['city'], axis = 1, inplace = True)

# let us confirm that we have dropped the unnecessary columns
result.head()

# Let us see if we have any null values
result.isnull().sum()
# we have no null values

# Checking for Anomalies
# Checking for outliers in the columns with numerical data

col_names = ['home_score', 'away_score']

fig, ax = plt.subplots(len(col_names), figsize=(10,10))

for i, col_val in enumerate(col_names):
    sns.boxplot(result[col_val], ax=ax[i])
    ax[i].set_title('Box plot - {}'.format(col_val), fontsize=10)
    ax[i].set_xlabel(col_val, fontsize=8)
plt.show()
# we have outliers

# let us print out the IQR for each numerical column
Q1 = result.quantile(0.25)
Q3 = result.quantile(0.75)
IQR = Q3 - Q1
print(IQR)

# let us drop the outliers and see hpw much data we lose
result_out = result[~((result < (Q1 - 1.5 * IQR)) |(result > (Q3 + 1.5 * IQR))).any(axis=1)]
result_out.shape
# outliers are 14,406 records. which is noy a big chunk of our data.

# We decided not to drop outliers 
# because dropping such a large part of our data would seriously affect the validity of our results 
# now that we have a clean dataset, let us carry out our analysis

# changing the date column to pandas datetime 
result.date = pd.to_datetime(result.date)
result.dtypes

"""### Merging"""

# let us check the unique values in the date of our ranking dataset
rank.rank_date.unique()
# the range is from 1993 to 2018

# let us check the unique values in the date of our results dataset
result.date.unique()
# the range is from 1872 to 2019

# since the ranking dataset begins in 1993 and ends in 2018
# let us filter our results dataset to only feature this timeframe
result1 = result[(result["date"] > '1993-01-01') &  (result["date"] < '2018-06-07')]
result1.shape

# let us change our date columns to reflect the year and month only

rank['year'] = rank.rank_date.dt.year
result1['year'] = result1.date.dt.year

rank['month'] = rank.rank_date.dt.month
result1['month'] = result1.date.dt.month

result1.columns

"""### Merging to get Home Rank"""

# let us rename our country column
rank.columns
rank.rename(columns={'country_full':'home_team'}, inplace=True)

# Let us now join our dataframes on the three columns they have in common
home = pd.merge(rank, result1, how='right', on=['home_team','year','month'])
home.head()

# let us get the shape of our merged dataframe
home.shape

# let us compare the shapes of all our dataframes
print(rank.shape)
print(result1.shape)
print(home.shape)

#let us check for duplicates
home.duplicated().sum()

# let us rename the rank column
home.rename(columns = {'rank': 'home_rank'}, inplace =True)
home.head()

# let us check for any null values in our merged dataframe
home.isnull().sum()

# Let us drop these null values
home.dropna(inplace=True)
home.isnull().sum()

# let us look at the resulting shape of our clea dataframe
home.shape

"""### Merging to get our Away Team Rank"""

#let us rename our country column
rank.columns
rank.rename(columns={'home_team':'away_team'}, inplace=True)

# Let us now join our dataframes on the three columns they have in common
away = pd.merge(rank, result1, how='right', on=['away_team','year','month'])
away.head()

# let us rename the rank column
away.rename(columns = {'rank': 'away_rank'}, inplace =True)
away.head()

# let us check for any null values in our merged dataframe
away.isnull().sum()

# Let us drop these null values
away.dropna(inplace=True)
away.isnull().sum()

away.shape

"""### Final Merge"""

# merging the final dataframe that will be used for analysis
df = pd.merge(home, away, how = 'inner', left_on = ['year', 'month','away_team'],
              right_on = ['year', 'month','away_team'])
df.head()

# let us check for any missing values
df.isnull().sum()
# we have no null values

# let us drop columns
df.drop(columns= ['date_x', 'country_x','rank_change_y','confederation_y','rank_date_y', 
'date_y','home_team_y','home_score_y','away_score_y','tournament_y','country_y',
'neutral_y', 'rank_date_x'], inplace=True)
df.head()

# let us rename our columns
df.rename(columns={'home_team_x':'home_team',
                   'rank_change_x':'rank_change',
                   'confederation_x':'confederation',
                   'home_score_x':'home_score',
                   'away_score_x':'away_score',
                   'tournament_x':'tournament',
                   'neutral_x':'neutral_x'},
                   inplace=True)
df.head()

# let us get the shape of our final dataframe
df.shape

# now with a clean dataframe, let us begin our analysis

"""# Adding Columns Useful for Our Analysis"""

# let us create a column to hold the win lose or draw result
df['goal_diff'] = df.home_score - df.away_score
df['result'] = df.home_score - df.away_score

# let us now define a funtion that will determine if a match is lose or win or draw
# from the perspective of our home team
a = df.home_score - df.away_score

def match_result(a):
  if a > 0:
    return 'WIN'
  elif a < 0:
    return 'LOSS'
  else:
    return 'DRAW'

# creating a new column to give the match outcome
df['result']= df.result.apply(lambda a: match_result(a))

# let us make sure our column has been added 
df.head()

# getting unique values of tournaments
df.tournament.unique()

# Creating a column to hold the tournament type

def type_tourn(i):
  if i == 'FIFA World Cup':
    return 'World Cup'
  elif i == 'Friendly':
    return 'Friendly'
  else:
    return 'Other'

df['tournament_type'] = df.tournament.apply(lambda x: type_tourn(x))

df.tournament_type.unique()

df.head()

# let us export our final dataframe to csv
df.to_csv('fifa.csv')

"""# Exploratory Data Analysis

### Univariate Analysis
"""

# # finding the information about the variables
df.info()

# findng summary statistics of our dataframe
df.describe()

# Bar graph showing tournaments

df.tournament.value_counts().head(10).sort_values().plot.barh()
plt.title('Tournaments')
# Friendly matches hold the top spot in the tournaments field

# Bar graph showing tournaments type

df.tournament_type.value_counts().head(10).sort_values().plot.bar()
plt.title('Tournament Types')
degrees = 60
plt.xticks(rotation=degrees)
# Other types of tournaments are played frequently (probably yearly) whereas,
# the worldcup has a low number of occurence since it is only played every four years

# let us check the distributions of our data
# we will use 

fig, axes = plt.subplots(2, 3, figsize=(18, 10))

fig.suptitle('Distribution of Numerical Data')

sns.distplot( df["home_rank"] , color="skyblue", ax=axes[0, 0])
sns.distplot( df["home_score"] , color="olive", ax=axes[0, 1])
sns.distplot( df["away_score"] , color="gold", ax=axes[0, 2])
sns.distplot( df["goal_diff"] , color="teal", ax=axes[1, 0])
sns.distplot( df["rank_change"] , color="teal", ax=axes[1, 1])
sns.distplot( df["away_rank"] , color="teal", ax=axes[1, 2])
# our data is normally distributed

# Bar graph showing confederations

df.confederation.value_counts().head(10).plot.bar()
plt.title('Confederations')
degrees = 60
plt.xticks(rotation=degrees)
# UEFA Confederations are the highest occuring in our dataframe

# pie chart visualizing the wins, loses and draws

df.result.value_counts().plot(kind= 'pie', figsize=[7,7], autopct = '%1.1f%%')
plt.title('A Pie chart of Results of the Match') 

# from the piechart, we can see that wins were almost half of the dataframe

"""### Bivariate Analysis"""

# Ploting the bivariate summaries and recording our observations
sns.pairplot(df)
plt.show()

# Calculating the pearson coefficient correlation
a = df.corr() 
plt.figure(figsize = (20,10))
sns.heatmap(a, xticklabels=a.columns, yticklabels=a.columns, annot=True)
plt.title('A Heatmap of Pearson Correlation in our Dataset')
plt.show()

# the bivariate analysis shows correlations between columns in our dataframe
# however there doesn't seem to be any high positie or negative correlation between the columns
# only the home score and goal difference have a high positive correlation to one one another (0.82)
# this is to be expected because when the home scores increase, so does the goal difference

"""# Predictive Analytics"""

# creating a copy
df2 = df.copy()

# Data for label encoding
df2['neutral_x'] = df2['neutral_x'].astype('category')
df2['tournament_type'] = df2['tournament_type'].astype('category')
df2['result'] = df2['result'].astype('category')

# Label encoding the categorical data

from sklearn.preprocessing import LabelEncoder

labelencoder = LabelEncoder()

df2['neutral_x'] = labelencoder.fit_transform(df2['neutral_x'])
df2['tournament_type'] = labelencoder.fit_transform(df2['tournament_type'])
df2['result'] = labelencoder.fit_transform(df2['result'])

"""### Polynomial Regression

### Predicting Home Team Score
"""

df2.describe()

from sklearn.preprocessing import PolynomialFeatures

from sklearn.model_selection import train_test_split

# Import LinearRegression method from sklearn linear_model library
from sklearn.linear_model import LinearRegression

#Declaring our Independent and Deendent variables 
X = df2[['home_rank', 'away_rank','tournament_type']]
y = df2['home_score']

# Displaying the correlations between the variables
# we exclude the home score since it is our target variable
X.corr()

"""Multicollinearity occurs when there are two or more independent variables in a multiple regression model, which have a high correlation among themselves. When some features are highly correlated, we might have difficulty in distinguishing between their individual effects on the dependent variable. Multicollinearity can be detected using various techniques, one such technique being the Variance Inflation Factor(VIF)."""

# Checking for Multicollinearity
# VIF dataframe 
from statsmodels.stats.outliers_influence import variance_inflation_factor
vif_data = pd.DataFrame() 
vif_data["feature"] = X.columns 
  
# calculating VIF for each feature 
vif_data["VIF"] = [variance_inflation_factor(X.values, i) 
                          for i in range(len(X.columns))] 
  
print(vif_data)

"""VIF exceeding 5 or 10 indicates high multicollinearity between this independent variable and the others.
our variables do not exceed 5
"""

# Split the dataset into train and test sets
X_train, y_train, X_test, y_test = train_test_split(X,y, test_size = 0.2, random_state=0)

# # Standardising the X_train and the X_test to the same scale
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
#X_train = scaler.fit_transform(X_train)
#X_test = scaler.transform(X_test)

# Fit polynomial Regression to the dataset
poly_reg = PolynomialFeatures(degree = 4) 
X_poly = poly_reg.fit_transform(X)

pol_reg = LinearRegression()
pol_reg.fit(X_poly, y)

# Running the prediction
y_pred = pol_reg.predict(X_poly)
y_pred

# evaluating our model
from sklearn import metrics
from sklearn.metrics import mean_squared_error, r2_score
rmse = np.sqrt(mean_squared_error(y, y_pred))
r2 = r2_score(y, y_pred)
print(rmse)
print(r2)

# our model yields an RMSE of 1.45
# and our R2 is 26%
# the RMSE is almost the value of the mean of our target variable
# thereby we may need to reevaluate our model and redefine our independent variables

"""### Predicting Away Team Score"""

df2.describe()

#Declaring our Independent and Dependent variables 
X = df2[['away_rank', 'home_rank','tournament_type']]
y = df2['away_score']

# Displaying the correlations between the variables
# we exclude the home score since it is our target variable
X.corr()

"""Multicollinearity occurs when there are two or more independent variables in a multiple regression model, which have a high correlation among themselves. When some features are highly correlated, we might have difficulty in distinguishing between their individual effects on the dependent variable. Multicollinearity can be detected using various techniques, one such technique being the Variance Inflation Factor(VIF)."""

# Checking for Multicollinearity
# VIF dataframe 
vif_data = pd.DataFrame() 
vif_data["feature"] = X.columns 
  
# calculating VIF for each feature 
vif_data["VIF"] = [variance_inflation_factor(X.values, i) 
                         for i in range(len(X.columns))] 
  
print(vif_data)

"""VIF exceeding 5 or 10 indicates high multicollinearity between this independent variable and the others.
our variables do not exceed 5
"""

# Split the dataset into train and test sets
X_train, y_train, X_test, y_test = train_test_split(X,y, test_size = 0.2, random_state=0)

# # Standardising the X_train and the X_test to the same scale
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
#X_train = scaler.fit_transform(X_train)
#X_test = scaler.transform(X_test)

# Fit polynomial Regression to the dataset
poly_reg = PolynomialFeatures(degree = 6) 
X_poly = poly_reg.fit_transform(X)

pol_reg = LinearRegression()
pol_reg.fit(X_poly, y)

# Running the prediction
y_pred = pol_reg.predict(X_poly)
y_pred

# evaluating our model
from sklearn import metrics
from sklearn.metrics import mean_squared_error, r2_score
rmse = np.sqrt(mean_squared_error(y, y_pred))
r2 = r2_score(y, y_pred)
print(rmse)
print(r2)

# our model has an RMSE of 1.15
# and our R2 is 20%
# The RMSE is almost the value of the mean of our target variable
# thereby we may need to reevaluate our model and redefine our independent variables

"""### Logistic Regression"""

# Checking our target variable

sns.countplot(x='result',data=df, palette='hls')

df2.head()

# Checking for independence between features¶
# 
plt.figure(figsize = (20,10))
sns.heatmap(df2.corr(), annot=True)

# Splitting our dataset
# We will drop all non-numerical data and data we have not encoded in our dataframe
X = df2.drop(["result", 'home_team', 'away_team','year','month','goal_diff', 'confederation', 'tournament'],axis=1)
y = df2["result"]

# Spliting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)

# Fitting our model
# 
from sklearn.linear_model import LogisticRegression

LogReg = LogisticRegression()
LogReg.fit(X_train, y_train)

# Using our model to make a prediction
#
y_pred = LogReg.predict(X_test)

# Measuring the accuracy of the model
#
from sklearn.metrics import accuracy_score
print(f'The accuracy of the model is {accuracy_score(y_test, y_pred)}')

# Evaluating the model
#
from sklearn.metrics import confusion_matrix
confusion_matrix = confusion_matrix(y_test, y_pred)
confusion_matrix

# The model above has an accuracy of 100% 
# The model is clearly overfitting on the training data; 
# Therefore we need to reevaluate our model

# Checking for Residuals in our predicted values

residuals = y_pred - y_test

# Plotting the prediction errors

plt.scatter(y_pred, residuals, color='black')
plt.title('Residual Plot')
plt.ylabel('residuals')
plt.xlabel('fitted values')
plt.axhline(y= residuals.mean(), color='orange')
plt.show()

# There are no residuals

"""### Hyperparameter Tuning

### Random Search
"""

#
X = df2.drop(["result", 'home_team', 'away_team','year','month','goal_diff', 'confederation', 'tournament'],axis=1)
y = df2["result"]

# Performing Data Preprocessing
# ---
X_train, X_test, y_train, y_test = train_test_split(X, y)

# random search logistic regression model on the fifa dataset
from scipy.stats import loguniform
from pandas import read_csv
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform

# define model
logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,random_state=0)

distributions = dict(C=uniform(loc=0, scale=4),penalty=['l2', 'l1'])

clf = RandomizedSearchCV(logistic, distributions, random_state=0)

search = clf.fit(X,y)

search.best_params_

# our best params are 'C': 2.195254015709299, 'penalty': 'l1'

# another method for random search 
#Random Search
# specify parameters and distributions to sample from
from scipy.stats import randint as sp_randint
from sklearn.ensemble import RandomForestClassifier

param_dist = {"max_depth": [3, None],
              "max_features": sp_randint(1, 11),
              "min_samples_split": sp_randint(2, 11),
              "bootstrap": [True, False],
              "criterion": ["gini", "entropy"]}

# Step 2: Instantiating RandomizedSearchCV object 
# ---
# 
from sklearn.model_selection import RandomizedSearchCV 
classifier = RandomForestClassifier(n_estimators=300, random_state=0)
random_sr = RandomizedSearchCV(classifier, param_dist, cv = 5) 

# Step 3: Calling the fit method
# ---
#
random_sr.fit(X_train, y_train)

# Step 4: Checking the parameters that return the highest accuracy
# ---
#
best_parameters = random_sr.best_params_
print(best_parameters)

# Finding the obtained accuracy
# --
# 
best_result = random_sr.best_score_
print(best_result)
# 
# using the parameters generated below would yield an accuracy of 99% for our model.

"""# Challenging the Solution

Our Polynomial Regression prediction models were not effective since the RMSE yielded was not ideal. 

Therefore we may need to use other prediction models to predict our home and away scores effectively.

Did we have the right data?
Yes we did because it has the information we need to do our predictons.
however, we need to use better predictive models instead of polynomial regression.

# Conclusions

We were able to analyse our datasets and come up with 
We have been able to create predictive models.


For our polynomial regression models, the RMSE are close to the mean of the target variables meaning that this type of predictive model may not the optimal model to use for this dataframe. 
We need to reevaluate our variables and explore other models to perform predictions


For our logistic regression, we were able to obtain a model with 100$ level of accuracy.
"""

